{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Cuda Programming Applications**\n",
        "\n",
        "This mini-lab targets some hands-on implementations and more practice on cuda in common real-world recurring tasks. Moreover, we aim to compare the outcomes of our low-level implementations with the built-in functions in popular frameworks as Pytorch. We'll revisit how you can fool cuda by passing a 2D array (for easier indexing)! Then we'll go straight to implement our Conv3D kernel function!"
      ],
      "metadata": {
        "id": "SACSa2bT_vc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Passing 2D array to cuda**\n",
        "\n",
        "As we already know, array memory representation in cuda is linear, making higher-dimensional arrays represented also in a 1D fashion. That's why we need to flatten a 2D matrix to pass it to cuda in a row-major representation, making indexing kind of tedious. Now the question that pops-up: Could we in any way pass a 2D-organised array to cuda to do a more convenient double indexing?\n",
        "\n",
        "The answer is: Yes! Yet, this comes with some limitations. To pass a 2D array and carry out double indexing in cuda, this array has to be statically allocated by the CPU, not dynamically allocated, so you need to know the array dimensions at the compile time. This way, the compiler is aware about the width of the 2D array, and can do the linearization process on its own. Moreover, a statically allocated array will be represented in memory in a contiguous 1D fashion. In contrast, if you dynamically allocate your matrix, you may or may not gurantee that all elements of the 2D array are contiguous, depending on the allocation fashion.\n",
        "\n",
        "    // Consider for example, allocating the array this way:\n",
        "\n",
        "    int* arr[r];\n",
        "    for (i = 0; i < r; i++)\n",
        "        arr[i] = (float*)malloc(c * sizeof(float));\n",
        "\n",
        "A call to malloc here does not necessarily gurantee that the allocated memory is just after its preceding ones. Such discontinuouty makes it hard for the compiler to carry out the linearization."
      ],
      "metadata": {
        "id": "h3MMzziQDLMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now let's consider the following matrix addition example based on double indexing"
      ],
      "metadata": {
        "id": "R-PSQaNJJiH8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tqpbDe__ib0"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <assert.h>\n",
        "#define N 1000\n",
        "#define M 500\n",
        "#define MAX_ERR 1e-3\n",
        "__global__ void MatAdd(float A[N][M], float B[N][M], float C[N][M])\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    // Note: the first indexing specifies the row (y-axis), the second one specifies the column (x-axis)\n",
        "    C[j][i] = A[j][i] + B[j][i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "     // statically allocate the matrices\n",
        "     float a[N][M], b[N][M], c[N][M];\n",
        "\n",
        "    // Initialize a, b\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < M; ++j) {\n",
        "            a[i][j] = i * 1.1;\n",
        "            b[i][j] = j * 1.1;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_A, *d_B, *d_C; // Device pointer for the 2D array\n",
        "\n",
        "    cudaMalloc((void**)&d_A, sizeof(float) * N * M);\n",
        "    cudaMalloc((void**)&d_B, sizeof(float) * N * M);\n",
        "    cudaMalloc((void**)&d_C, sizeof(float) * N * M);\n",
        "\n",
        "    // Transfer data from host to device memory\n",
        "    cudaMemcpy(d_A, a, sizeof(float) * N * M, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, b, sizeof(float) * N * M, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 ThreadsPerBlock(16, 16);\n",
        "\n",
        "    // Note that M here specifies the number of columns (on the X-axis), while N specifies the rows\n",
        "    dim3 GridSize ((M - 1) / ThreadsPerBlock.x + 1, (N - 1) / ThreadsPerBlock.y + 1);\n",
        "\n",
        "    // Casting the single pointer to an array of pointers\n",
        "    MatAdd<<<GridSize, ThreadsPerBlock>>>((float(*) [M])d_A, (float(*) [M])d_B, (float(*) [M])d_C);\n",
        "\n",
        "    // Transfer data back to host memory\n",
        "    cudaMemcpy(c, d_C, sizeof(float) * N * M, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    // Verification\n",
        "    for(int i = 0; i < N; i++){\n",
        "      for(int j = 0; j < M; j++){\n",
        "         assert(fabs(c[i][j] - a[i][j] - b[i][j]) < MAX_ERR);\n",
        "      }\n",
        "    }\n",
        "    printf(\"PASSED\\n\");\n",
        "\n",
        "    // Deallocate device memory\n",
        "     cudaFree(d_A);\n",
        "     cudaFree(d_B);\n",
        "     cudaFree(d_C);\n",
        "\n",
        "    // No need to deallocate host memory\n",
        "}"
      ],
      "metadata": {
        "id": "PcoBAeRwKF39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Requirement**\n",
        "\n",
        "A) A cuda program is required to carry out a 3D convolution over RGB images and save the output ones, the program is given a path to a folder containing the input images and that of an output folder that should contain the outputs, respectively as command line arguments.\n",
        "\n",
        "1.   kernel1: basic implementation (no tiling)\n",
        "2.   kernel2: tiling where each block matches the input tile size.\n",
        "3.   kernel3: tiling where each block matches the output tile size.\n",
        "\n",
        "Notes:\n",
        "*   Add necessary paddings so that the output image size is the same as that of the input one.\n",
        "\n",
        "*   The kernel should be able to handle a batch of images at a time, the batch size is passed as the 3rd argument.\n",
        "*   The mask is given in a .txt file, whose path is passed as the 4th argument. The first line contains its dimension n (one number only as it's a square mask) then the consecutive n lines contain the mask rows, each row in a separate line. Repeat the mask 3 times for the 3 channels of the image.\n",
        "\n",
        "  Ex: ./a.out input_folder_path output_folder_path 4 mask.txt\n",
        "\n",
        "B) Implement the same program in python, using the built-in convolution functions in Pytorch.\n",
        "\n",
        "C) Profile each program carefully and do sufficient experiments to compare between them and collect insightful results. Organise your results in a tabular form and prepare a comprehensive report explaining all of your findings. Also mention the impact of declaring the mask as constant in terms of execution time and elaborate on this in your report."
      ],
      "metadata": {
        "id": "9DU7eXap6ZpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Helpers**\n",
        "\n",
        "This section contains some helpers that could be needed for the requirement. Check it frequently.\n",
        "\n",
        "**Helper1**: Read RGB images in C"
      ],
      "metadata": {
        "id": "Lc-0dlsfvh1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch stb_image library\n",
        "\n",
        "!git clone https://github.com/nothings/stb.git\n",
        "!cp stb/stb_image.h /usr/local/include/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCT_z26pv281",
        "outputId": "26a289f0-1e9f-4264-810b-504d74b89d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stb'...\n",
            "remote: Enumerating objects: 8031, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 8031 (delta 99), reused 104 (delta 78), pack-reused 7868\u001b[K\n",
            "Receiving objects: 100% (8031/8031), 5.59 MiB | 12.25 MiB/s, done.\n",
            "Resolving deltas: 100% (5324/5324), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the image dimensions and pixels\n",
        "\n",
        "%%writefile read_image.c\n",
        "#define STB_IMAGE_IMPLEMENTATION\n",
        "\n",
        "#include <stdio.h>\n",
        "#include \"stb_image.h\"\n",
        "\n",
        "const size_t NUM_PIXELS_TO_PRINT = 10;\n",
        "\n",
        "int main(void) {\n",
        "    int width, height, comp;\n",
        "    unsigned char *data = stbi_load(\"image.jpeg\", &width, &height, &comp, 0);\n",
        "    if (data) {\n",
        "        printf(\"width = %d, height = %d, comp = %d (channels)\\n\", width, height, comp);\n",
        "        for (size_t i = 0; i < NUM_PIXELS_TO_PRINT * comp; i++) {\n",
        "            printf(\"%d%s\", data[i], ((i + 1) % comp) ? \" \" : \"\\n\");\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMC7DrRHwgsd",
        "outputId": "a93a1f79-7676-46ca-f676-43baf3bc3a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting read_image.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ read_image.c -o readImage.out\n",
        "!./readImage.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6kZE3q6zcqX",
        "outputId": "b9447446-b5a8-4f13-acd4-a5dc94efed1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "width = 989, height = 1280, comp = 3 (channels)\n",
            "153 161 161\n",
            "153 161 161\n",
            "153 161 161\n",
            "153 161 161\n",
            "153 161 161\n",
            "153 161 161\n",
            "153 161 161\n",
            "153 161 161\n",
            "152 160 160\n",
            "152 160 160\n",
            "\n"
          ]
        }
      ]
    }
  ]
}